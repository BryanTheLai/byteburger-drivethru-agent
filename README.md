@elevenlabs-agent.md @supabase-setup.md @README.md 


# ByteBurger Drive-Thru Voice Ordering System



An app for voice-driven drive-thru ordering using ElevenLabs Conversational AI Agent + CRUD backend (Supabase).
You play the customer ("car-001", "car-002", â€¦), talk to the Agent, confirm order, then the system records the order in database; kitchen staff views pending and done orders.



---



## ğŸ¯ Overview & Goals



* Use an **ElevenLabs Agent** with a client tool `place_order_after_confirmation` to take simple orders from customers.
* Hardcoded menu of exactly **5 items**: ByteBurger, NanoFries, Quantum Nuggets, Code Cola, Debug Shake.
* Each car/session has its own **car\_id**, auto-incremented (car-001, car-002, â€¦).
* Agent must repeat back order counts for confirmation before calling the tool.
* Once confirmed, store order in Supabase.
* Two screens:



Â  1. **Drive-Thru UI** (customer side): talk to agent, simulate car, fake receipt, next car.
Â  2. **Kitchen UI**: view orders (pending & done), mark done, refresh every 5 seconds.
* Include a mute button and voice animation to show speaking state of both the user and the agent.


---



## ğŸ² Menu



* ByteBurger
* NanoFries
* Quantum Nuggets
* Code Cola
* Debug Shake



---



## ğŸ”§ Agent Configuration & Client Tool



### Client Tool: `place_order_after_confirmation`



* **Name**: `place_order_after_confirmation`
* **Description**: â€œRecords a confirmed order to the kitchen system. Use only after the user confirms counts.â€
* **Parameters**:



```json
{
Â  "type": "object",
Â  "properties": {
Â  Â  "car_id": { "type": "string" },
Â  Â  "items": {
Â  Â  Â  "type": "array",
Â  Â  Â  "items": {
Â  Â  Â  Â  "type": "object",
Â  Â  Â  Â  "properties": {
Â  Â  Â  Â  Â  "item": { "type": "string" },
Â  Â  Â  Â  Â  "qty": { "type": "integer", "minimum": 1 }
Â  Â  Â  Â  },
Â  Â  Â  Â  "required": ["item","qty"]
Â  Â  Â  },
Â  Â  Â  "minItems": 1
Â  Â  }
Â  },
Â  "required": ["car_id","items"]
}
```



* **Return**: simple string, e.g. `"order-recorded:123"`.



### System Prompt (Agent)



```
You are the ByteBurger Drive-Thru agent.



Menu (only these 5 items are available):
- ByteBurger
- NanoFries
- Quantum Nuggets
- Code Cola
- Debug Shake



Rules:
- Always keep responses short and snappy.
- When the user orders, repeat back exact counts to confirm (e.g., "2 ByteBurgers and 1 Code Cola. Is that correct?").
- Only after the user clearly confirms, call the client tool `place_order_after_confirmation` with the current `car_id` and the confirmed items.
 - When the user orders, repeat back exact counts to confirm (e.g., "2 ByteBurgers and 1 Code Cola. Is that correct?").
 - Only after the user clearly confirms, call the client tool `place_order_after_confirmation` with the current `car_id` and the confirmed items.
 - Do NOT invent or accept any items outside the menu.
 - If asked for something else, politely say itâ€™s not available and offer the menu items.
 - After tool call, say itâ€™s been placed, please move to the next counter. Then end the call.
```



---



## ğŸ— Core Architecture



Hereâ€™s how the pieces should be set up (UI, agent, database, tools).



### Components



| Component Â  Â  Â  Â  Â  Â | Responsibility Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  |
| -------------------- | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------ |
| **Drive-Thru UI** Â  Â | Shows greeting, mic / WebRTC conversation via `@elevenlabs/react`, listens for car/customer voice, displays recognized text, handles â€œYesâ€ confirmation, shows receipt. Auto increments `car_id` each new order. Mute button + animation during voice. |
| **Kitchen UI** Â  Â  Â  | Connects to Supabase, shows list of all orders, grouped by status (`pending` / `done`), allows marking orders done, refresh every 5s + manual refresh. Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  |
| **Backend API** Â  Â  Â | Next.js server routes that talk to Supabase: record\_order route (though Agent calls client tool which triggers server route), fetch orders, mark done. Also token route for Agent WebRTC. Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  |
| **ElevenLabs Agent** | Configured via Dashboard (per your prompt + tool). Agent SDK client in the Drive-Thru UI: starts session with WebRTC, has available tool `record_order`. Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  |



### Data Storage



Supabase table:



```sql
create table public.orders (
Â  id serial primary key,
Â  car_id text not null,
Â  items jsonb not null,
Â  status text not null default 'pending',
Â  created_at timestamptz not null default now()
);
```



* `car_id`: auto-incrementing like `"car-001"`, `"car-002"`.
* `items`: JSON array of `{ item: string, qty: integer }`.
* `status`: `'pending'` or `'done'`.
* `created_at`: timestamp.



### Flow



1. UI loads â†’ fetch next car\_id (you can compute client-side via supabase query: max existing or start at â€œcar-001â€ if none).
2. Start agent session using `@elevenlabs/react` with system prompt & tool.
3. User orders via voice: e.g. â€œI want 2 ByteBurgers and a Code Cola.â€
4. Agent repeats exactly: â€œ2 ByteBurgers and 1 Code Cola. Is that correct?â€
5. User says â€œYes.â€
6. Agent calls `place_order_after_confirmation` tool with `{ car_id: â€œcar-XXXâ€, items: [ â€¦ ] }`.
7. Backend route receives tool call, inserts into `orders` table.
8. UI shows â€œOrder placedâ€ + fake receipt. Then increment car\_id for next order (car-002).
9. Kitchen UI refreshes, sees new order, staff clicks â€œMark as Doneâ€ â†’ status update.



---



## ğŸ›  Requirements & Tech Stack



* **Library**: `@elevenlabs/react` (Agent SDK) for WebRTC voice conversation.
* **Supabase**: for database, real storage.
* **Next.js**: front + server.
* **localStorage**: for Drive-Thru UI session state if needed (for receipt visibility, car\_id persistence).
* **Environment Variables**:



```
NEXT_PUBLIC_SUPABASE_URL_URL=â€¦
SUPABASE_SERVICE_ROLE_KEY=â€¦
ELEVENLABS_API_KEY=â€¦
ELEVENLABS_AGENT_ID=â€¦
```



---



## ğŸ¬ Demo Safety & Enhancements



* Pre-seed kitchen with a few fake â€œpendingâ€ orders so Kitchen UI isnâ€™t empty.
* Make a **demo script**: you practice one full order flow (customer speaks, confirms, places, show receipt, kitchen sees, mark done).
* Mute button + voice animation so audience sees when the agent or car is speaking.
* If voice fails, always fallback to manual input for order.
* Auto car\_id reset or explicit clear before demo.



---



## âœ… Success Criteria



* Drive-Thru UI: user can talk to agent or manually input order, confirm, see receipt, car\_id increments.
* Agent does *not* accept invalid menu items.
* Orders inserted into Supabase, kitchen sees pending orders, can mark done.
* Kitchen UI refreshes every \~5s.
* No weird agent hallucinations; flow stays on script.



---
```app/api/conversation-token/route.ts
import { NextResponse } from "next/server"


export async function GET(): Promise<NextResponse> {
Â  const apiKey = process.env.ELEVENLABS_API_KEY
Â  const agentId = process.env.ELEVENLABS_AGENT_ID
Â  if (!apiKey || !agentId) {
Â  Â  return NextResponse.json({ error: "Missing ELEVENLABS_API_KEY or ELEVENLABS_AGENT_ID" }, { status: 500 })
Â  }
Â  const url = `https://api.elevenlabs.io/v1/convai/conversation/token?agent_id=${encodeURIComponent(agentId)}`
Â  const resp = await fetch(url, {
Â  Â  headers: { "xi-api-key": apiKey },
Â  Â  cache: "no-store",
Â  })
Â  if (!resp.ok) {
Â  Â  return NextResponse.json({ error: "Failed to get conversation token" }, { status: 500 })
Â  }
Â  const body = (await resp.json()) as { token: string }
Â  return NextResponse.json({ token: body.token })
}


```


Use this route.ts, it just works.


You will probably need something like this in page.tsx for the customer facing side:
```code from other project, dynamic variables and client are not the same as for byteburger!!
Â  try {
Â  Â  Â  Â  await conversation.startSession({
Â  Â  Â  Â  Â  conversationToken: j.token,
Â  Â  Â  Â  Â  connectionType: "webrtc",
Â  Â  Â  Â  Â  dynamicVariables: {
Â  Â  Â  Â  Â  Â  product_name: productName,
Â  Â  Â  Â  Â  Â  product_description: productDescription,
Â  Â  Â  Â  Â  Â  base_price: basePrice,
Â  Â  Â  Â  Â  Â  sticker_price: stickerPrice,
Â  Â  Â  Â  Â  Â  policy_confidential_competition: true,
Â  Â  Â  Â  Â  Â  session_id: sid,
Â  Â  Â  Â  Â  },
Â  Â  Â  Â  Â  clientTools: {
Â  Â  Â  Â  Â  Â  // allow the agent to report the numeric offer it heard
Â  Â  Â  Â  Â  Â  set_user_offer: ({ offer }: { offer: number }): string => {
Â  Â  Â  Â  Â  Â  Â  try {
Â  Â  Â  Â  Â  Â  Â  Â  const n = Math.max(0, Math.floor(Number(offer) || 0))
Â  Â  Â  Â  Â  Â  Â  Â  // update both ref and React state so UI updates immediately.
Â  Â  Â  Â  Â  Â  Â  Â  // Avoid setting identical values to reduce re-renders.
Â  Â  Â  Â  Â  Â  Â  Â  if (stateRef.current.userOffer !== n) {
Â  Â  Â  Â  Â  Â  Â  Â  Â  stateRef.current.userOffer = n
Â  Â  Â  Â  Â  Â  Â  Â  Â  setUserOffer(n)
Â  Â  Â  Â  Â  Â  Â  Â  }
Â  Â  Â  Â  Â  Â  Â  Â  console.info("[clientTool] set_user_offer called ->", n)
Â  Â  Â  Â  Â  Â  Â  Â  // emit a DOM event so you can observe tool calls from the browser console
Â  Â  Â  Â  Â  Â  Â  Â  try {
Â  Â  Â  Â  Â  Â  Â  Â  Â  window.dispatchEvent(new CustomEvent("elevenlabs-client-tool", { detail: { tool: "set_user_offer", parameters: { offer: n } } }))
Â  Â  Â  Â  Â  Â  Â  Â  } catch { }
Â  Â  Â  Â  Â  Â  Â  Â  return `ok:reported:${n}`
Â  Â  Â  Â  Â  Â  Â  } catch (e) {
Â  Â  Â  Â  Â  Â  Â  Â  return `error`
Â  Â  Â  Â  Â  Â  Â  }
Â  Â  Â  Â  Â  Â  },
Â  Â  Â  Â  Â  },
Â  Â  Â  Â  })
Â  ```



Use context7 tool call or deepwiki or websearch, whatever you need to do to make sure this app works.
Make sure write readme of what i need to do from my part, like in elevenlabs dashboard.
write the skeleton and core logic, make sure everything works.
Research as much as you need, then plan and execute.
Make sure to follow what i said.
Keep things minimal, make sure they all work.
Make sure for each new person, car, use localStorage.clear() before starting.

Create in this repository.

## ğŸš€ Setup & Run

### 1) Prerequisites

- Node 18+
- An ElevenLabs account with Conversational AI Agents enabled
- A Supabase project

### 2) Environment Variables

Create a `.env.local` file at the repository root with:

```
SUPABASE_URL=your_supabase_project_url
SUPABASE_SERVICE_ROLE_KEY=your_service_role_key
ELEVENLABS_API_KEY=your_elevenlabs_api_key
ELEVENLABS_AGENT_ID=your_agent_id
```

Do not commit secrets.

### 3) Supabase Table

Open `docs/supabase-setup.md` and copy/paste the SQL into the Supabase SQL editor to create the `orders` table. Optional indexes are included.

### 4) ElevenLabs Agent Dashboard

Open `docs/elevenlabs-agent.md` and follow the steps to:

- Create the Client Tool `record_order` with the provided JSON schema
- Set the System Prompt exactly as shown
- Use your preferred voice

Copy the Agent ID into `.env.local` as `ELEVENLABS_AGENT_ID`.

### 5) Install & Run

```
npm install
npm run dev
```

Open http://localhost:3000 for Drive-Thru and http://localhost:3000/kitchen for Kitchen.

## ğŸ§­ How To Use

### Drive-Thru

- Click `Start Voice Order` to begin a WebRTC session with the Agent
- Speak your order; the Agent will repeat counts to confirm
- Say "Yes" to confirm; the Agent calls `record_order` and the order is inserted
- A receipt appears; click `Next Car` to advance the `car_id`
- Use `Mute` if needed; the green dot indicates Agent speaking; red indicates idle/muted
- Manual fallback: type quantities and click `Confirm Manual Order`

### Kitchen

- Visit `/kitchen` to see `pending` and `done` orders
- Click `Mark Done` to move an order to done
- Auto-refreshes every ~5 seconds; click `Refresh` to force reload
- Click `Seed Demo Orders` to pre-populate pending rows for demos

## ğŸ” Notes

- Server routes use the Supabase Service Role key; keep it only in server environment variables
- The conversation token endpoint is implemented at `app/api/conversation-token/route.ts`
- Each new session clears `localStorage` before starting

## ğŸ§ª Demo Flow

1. Load `/kitchen`, click `Seed Demo Orders`
2. Load `/`, click `Start Voice Order`
3. Order: "Two ByteBurgers and one Code Cola"
4. Agent confirms counts; say "Yes"
5. Receipt appears; Kitchen shows a new pending order
6. In Kitchen, click `Mark Done`

## ğŸ†˜ Troubleshooting

- If `Start Voice Order` fails, verify `.env.local` is set and restart the dev server
- Ensure your browser has microphone permissions
- Confirm the Agent has the `record_order` tool configured with the correct JSON schema
- Supabase insert errors usually mean environment variables are missing or table not created